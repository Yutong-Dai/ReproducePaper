{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import utils\n",
    "import cv2\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Image:./db/lehigh.jpg | Style Image:./db/monnet.jpg | savename: trm-lehigh-monnet\n"
     ]
    }
   ],
   "source": [
    "c='./db/lehigh.jpg'; s='./db/monnet.jpg'; savename='trm-lehigh-monnet'\n",
    "G_pretrained=None; epochs=100; c_layer=5; alpha=1; beta=1e4; printevery=100; starting=0\n",
    "print(f\"Content Image:{c} | Style Image:{s} | savename: {savename}\", flush=True)\n",
    "# load model\n",
    "model = models.vgg19(pretrained=True)\n",
    "model = model.cuda()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# load image\n",
    "# contentImage\n",
    "img = cv2.imread(c)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "h, w, c = img.shape\n",
    "contentImage = torch.tensor(img / 255.0).float().cuda()\n",
    "# style image\n",
    "img = cv2.imread(s)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (w, h))\n",
    "styleImage = torch.tensor(img / 255.0).float().cuda()\n",
    "layers = utils.get_layers(model)\n",
    "\n",
    "aCs = utils.get_feature_maps(contentImage, layers)\n",
    "aSs = utils.get_feature_maps(styleImage, layers)\n",
    "if G_pretrained != 'None':\n",
    "    G = G_pretrained\n",
    "else:\n",
    "    # torch.manual_seed(0)\n",
    "    # G = torch.rand(contentImage.shape, requires_grad=True, device=\"cuda\")\n",
    "    G = contentImage.detach().clone().requires_grad_(True).cuda()\n",
    "style_layer_weights = [1.0 / 16 for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = contentImage.detach().clone().requires_grad_(True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:2.625e+02 | content: 0.000e+00 | style_cost:2.625e-02\n"
     ]
    }
   ],
   "source": [
    "del gradf \n",
    "del loss\n",
    "aGs = utils.get_feature_maps(G, layers)\n",
    "loss, content_cost, style_cost = utils.compute_total_cost(aGs, aCs, aSs, style_layer_weights,\n",
    "                                         content_layer_idx=c_layer, alpha=alpha, beta=beta)\n",
    "print(f'loss:{loss.data.cpu().item():2.3e} | content: {content_cost.item():2.3e} | style_cost:{style_cost.item():2.3e}', flush=True)\n",
    "gradf = torch.autograd.grad(loss, [G], create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 1.5126e-03,  3.3881e-03,  1.7188e-03],\n",
      "         [ 1.7857e-03,  4.2745e-03,  2.0127e-03],\n",
      "         [ 1.6648e-03,  3.0428e-03,  1.4370e-03],\n",
      "         ...,\n",
      "         [-9.8722e-05, -2.6517e-04, -8.8545e-05],\n",
      "         [ 3.9613e-05,  3.4186e-05,  1.8595e-04],\n",
      "         [-1.9084e-04, -1.7486e-04,  8.3391e-05]],\n",
      "\n",
      "        [[ 9.5865e-04,  4.1314e-03,  1.7809e-03],\n",
      "         [ 5.0751e-03,  1.0413e-02,  4.2353e-03],\n",
      "         [ 2.5532e-03,  4.2267e-03, -4.1913e-04],\n",
      "         ...,\n",
      "         [ 5.3267e-04,  7.0275e-04,  3.9367e-04],\n",
      "         [-3.0328e-04,  1.5079e-04,  4.9799e-04],\n",
      "         [-5.2780e-04, -2.1413e-04,  2.5662e-04]],\n",
      "\n",
      "        [[-1.4387e-03, -3.6144e-04, -6.9945e-04],\n",
      "         [ 1.1432e-03,  3.8626e-03,  4.9958e-04],\n",
      "         [ 1.8936e-03,  1.5596e-03, -1.4637e-03],\n",
      "         ...,\n",
      "         [-6.7806e-04, -7.0182e-04, -1.3053e-05],\n",
      "         [-7.1567e-04, -2.4609e-04,  5.4547e-04],\n",
      "         [-3.2619e-04,  2.0573e-04,  4.9908e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 9.0206e-04,  1.0395e-03,  1.4286e-04],\n",
      "         [ 1.5657e-03,  6.4630e-04, -1.1185e-03],\n",
      "         [-7.4797e-04, -1.0326e-03, -4.6925e-04],\n",
      "         ...,\n",
      "         [ 1.3211e-03,  3.9694e-04, -1.5198e-04],\n",
      "         [ 6.8462e-04, -1.8582e-04, -3.6832e-04],\n",
      "         [-2.4345e-04, -3.2690e-04, -7.8787e-05]],\n",
      "\n",
      "        [[ 1.4186e-03,  9.8533e-04, -4.7967e-04],\n",
      "         [ 3.4227e-03,  2.3309e-03, -7.8286e-04],\n",
      "         [ 1.0596e-03,  1.0795e-03, -7.3747e-05],\n",
      "         ...,\n",
      "         [ 1.3577e-03,  1.5321e-03,  4.0155e-04],\n",
      "         [ 1.0341e-03,  6.3832e-04,  5.8018e-05],\n",
      "         [ 1.4346e-04,  3.0931e-04,  2.2130e-04]],\n",
      "\n",
      "        [[-2.5759e-04, -3.1315e-04, -1.9442e-04],\n",
      "         [ 5.0785e-04,  4.8597e-04, -5.3823e-05],\n",
      "         [-1.3127e-04,  8.7910e-04,  9.2329e-04],\n",
      "         ...,\n",
      "         [ 1.9513e-04,  9.4764e-04,  4.5705e-04],\n",
      "         [ 2.8173e-04,  4.3428e-04,  1.9376e-04],\n",
      "         [-1.0216e-04,  2.1706e-04,  2.0412e-04]]], device='cuda:0'),)\n"
     ]
    }
   ],
   "source": [
    "d = torch.zeros_like(G) + 1\n",
    "Hd = torch.autograd.grad(gradf, G, d, retain_graph=False)\n",
    "print(Hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:2.625e+02 | content: 0.000e+00 | style_cost:2.625e-02\n",
      "tensor(16.5180, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "(tensor([[[ 1.5126e-03,  3.3881e-03,  1.7188e-03],\n",
      "         [ 1.7857e-03,  4.2745e-03,  2.0127e-03],\n",
      "         [ 1.6648e-03,  3.0428e-03,  1.4370e-03],\n",
      "         ...,\n",
      "         [-9.8722e-05, -2.6517e-04, -8.8545e-05],\n",
      "         [ 3.9613e-05,  3.4186e-05,  1.8595e-04],\n",
      "         [-1.9084e-04, -1.7486e-04,  8.3391e-05]],\n",
      "\n",
      "        [[ 9.5865e-04,  4.1314e-03,  1.7809e-03],\n",
      "         [ 5.0751e-03,  1.0413e-02,  4.2353e-03],\n",
      "         [ 2.5532e-03,  4.2267e-03, -4.1913e-04],\n",
      "         ...,\n",
      "         [ 5.3267e-04,  7.0275e-04,  3.9367e-04],\n",
      "         [-3.0328e-04,  1.5079e-04,  4.9799e-04],\n",
      "         [-5.2780e-04, -2.1413e-04,  2.5662e-04]],\n",
      "\n",
      "        [[-1.4387e-03, -3.6144e-04, -6.9945e-04],\n",
      "         [ 1.1432e-03,  3.8626e-03,  4.9958e-04],\n",
      "         [ 1.8936e-03,  1.5596e-03, -1.4637e-03],\n",
      "         ...,\n",
      "         [-6.7806e-04, -7.0182e-04, -1.3053e-05],\n",
      "         [-7.1567e-04, -2.4609e-04,  5.4547e-04],\n",
      "         [-3.2619e-04,  2.0573e-04,  4.9908e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 9.0206e-04,  1.0395e-03,  1.4286e-04],\n",
      "         [ 1.5657e-03,  6.4630e-04, -1.1185e-03],\n",
      "         [-7.4797e-04, -1.0326e-03, -4.6925e-04],\n",
      "         ...,\n",
      "         [ 1.3211e-03,  3.9694e-04, -1.5198e-04],\n",
      "         [ 6.8462e-04, -1.8582e-04, -3.6832e-04],\n",
      "         [-2.4345e-04, -3.2690e-04, -7.8787e-05]],\n",
      "\n",
      "        [[ 1.4186e-03,  9.8533e-04, -4.7967e-04],\n",
      "         [ 3.4227e-03,  2.3309e-03, -7.8286e-04],\n",
      "         [ 1.0596e-03,  1.0795e-03, -7.3747e-05],\n",
      "         ...,\n",
      "         [ 1.3577e-03,  1.5321e-03,  4.0155e-04],\n",
      "         [ 1.0341e-03,  6.3832e-04,  5.8018e-05],\n",
      "         [ 1.4346e-04,  3.0931e-04,  2.2130e-04]],\n",
      "\n",
      "        [[-2.5759e-04, -3.1315e-04, -1.9442e-04],\n",
      "         [ 5.0785e-04,  4.8597e-04, -5.3823e-05],\n",
      "         [-1.3127e-04,  8.7910e-04,  9.2329e-04],\n",
      "         ...,\n",
      "         [ 1.9513e-04,  9.4764e-04,  4.5705e-04],\n",
      "         [ 2.8173e-04,  4.3428e-04,  1.9376e-04],\n",
      "         [-1.0216e-04,  2.1706e-04,  2.0412e-04]]], device='cuda:0'),)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aGs = utils.get_feature_maps(G, layers)\n",
    "loss, content_cost, style_cost = utils.compute_total_cost(aGs, aCs, aSs, style_layer_weights,\n",
    "                                         content_layer_idx=c_layer, alpha=alpha, beta=beta)\n",
    "print(f'loss:{loss.data.cpu().item():2.3e} | content: {content_cost.item():2.3e} | style_cost:{style_cost.item():2.3e}', flush=True)\n",
    "gradf = torch.autograd.grad(loss, [G], create_graph=True)\n",
    "d = torch.zeros_like(G) + 1.0\n",
    "temp = (gradf[0] * d).sum()\n",
    "print(temp)\n",
    "Hd = torch.autograd.grad(temp, G, retain_graph=False)\n",
    "print(Hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 6.073522567749023 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "mem = float(torch.cuda.memory_allocated() / (1024 * 1024*1024))\n",
    "print(\"memory allocated:\", mem, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:2.625e+02 | content: 0.000e+00 | style_cost:2.625e-02\n",
      "tensor(16.5179, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 14.76 GiB total capacity; 13.61 GiB already allocated; 83.44 MiB free; 13.82 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-18387c48bda3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mHd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         inputs, allow_unused)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 14.76 GiB total capacity; 13.61 GiB already allocated; 83.44 MiB free; 13.82 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "del gradf \n",
    "del loss\n",
    "aGs = utils.get_feature_maps(G, layers)\n",
    "loss, content_cost, style_cost = utils.compute_total_cost(aGs, aCs, aSs, style_layer_weights,\n",
    "                                         content_layer_idx=c_layer, alpha=alpha, beta=beta)\n",
    "print(f'loss:{loss.data.cpu().item():2.3e} | content: {content_cost.item():2.3e} | style_cost:{style_cost.item():2.3e}', flush=True)\n",
    "gradf = torch.autograd.grad(loss, [G], create_graph=True)\n",
    "d = torch.zeros_like(G) + 1.0\n",
    "temp = (gradf[0] * d).sum()\n",
    "print(temp)\n",
    "Hd = torch.autograd.grad(temp, G, retain_graph=True)\n",
    "print(Hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 8.502850532531738 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "mem = float(torch.cuda.memory_allocated() / (1024 * 1024*1024))\n",
    "print(\"memory allocated:\", mem, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "File: TrustRegionCG.py\n",
    "Author: Yutong Dai (yutongdai95@gmail.com)\n",
    "File Created: 2021-04-13 22:25\n",
    "Last Modified: 2021-04-14 21:51\n",
    "--------------------------------------------\n",
    "Description:\n",
    "'''\n",
    "import torch\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TrusRegionCG:\n",
    "    def __init__(self, x, radius_init=0.1, radius_max=10, eta=0.2):\n",
    "        \"\"\"\n",
    "            x (list): a list of parameters; model.parameters()\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.device = x[0].device.type\n",
    "        self.radius = radius_init\n",
    "        self.radius_max = radius_max\n",
    "        self.eta = eta\n",
    "\n",
    "        self.cgmaxiter = 0\n",
    "        for e in x:\n",
    "            self.cgmaxiter += len(e.view(-1))\n",
    "\n",
    "    def _steihaug(self, gradf, radius):\n",
    "        \"\"\"\n",
    "            reference: P171. Numerical Optization (Stephan & Jorge) 2ed;\n",
    "        \"\"\"\n",
    "        self.cg_iter = 0\n",
    "        z = []\n",
    "        for e in self.x:\n",
    "            z.append(torch.zeros_like(e))\n",
    "        r = []\n",
    "        d = []\n",
    "\n",
    "        # calculate the norm of the gradient at the starting point\n",
    "        norm_gradf0 = 0.0\n",
    "        for e in gradf:\n",
    "            # +0.0 to do a copy\n",
    "            r.append(e.data + 0.0)\n",
    "            d.append(0.0 - e.data)\n",
    "            norm_gradf0 += torch.norm(e.data)**2\n",
    "        norm_gradf0 = (norm_gradf0.data.item()) ** 0.5\n",
    "        self.norm_gradf0 = norm_gradf0\n",
    "        cg_tol = min(0.5, norm_gradf0**0.5) * norm_gradf0\n",
    "        if norm_gradf0 < cg_tol:\n",
    "            self.cgflag = 'cgtol'\n",
    "            return z\n",
    "        while True:\n",
    "            self.cg_iter += 1\n",
    "            # check termination\n",
    "            if self.cg_iter > self.cgmaxiter:\n",
    "                print(\"Reach cg max iterations!\")\n",
    "                d = z\n",
    "                self.cgflag = 'cgmax'\n",
    "                break\n",
    "            # hessian vector product\n",
    "            print(d[0].shape, self.x[0].shape, gradf[0].shape)\n",
    "            gradf_direct = 0.0\n",
    "            ind = 0\n",
    "            for i in gradf:\n",
    "                gradf_direct += (i * d[ind]).sum()\n",
    "                ind += 1\n",
    "            print(gradf_direct)\n",
    "            Hd = torch.autograd.grad(gradf_direct, self.x, retain_graph=True)\n",
    "            # Hd = torch.autograd.grad(gradf, self.x, d, retain_graph=True)\n",
    "            # negative curvature test\n",
    "            dtHd = 0.0\n",
    "            for idx, hd in enumerate(Hd):\n",
    "                dtHd += (hd * d[idx]).sum()\n",
    "            if dtHd.data.item() <= 0.0:\n",
    "                tau = self._findroots(z, d, radius)\n",
    "                for idx in range(len(self.x)):\n",
    "                    d[idx] = z[idx] + tau * d[idx]\n",
    "                self.cgflag = 'negcv'\n",
    "                break\n",
    "            # positive curvature\n",
    "\n",
    "            norm_r_sq = 0.0\n",
    "            for e in r:\n",
    "                norm_r_sq += (e * e).sum()\n",
    "            alpha = (norm_r_sq / dtHd).data.item()\n",
    "\n",
    "            znew = []\n",
    "            norm_znew = 0.0\n",
    "            for idx in range(len(self.x)):\n",
    "                trial = z[idx] + alpha * d[idx] + 0.0\n",
    "                znew.append(trial)\n",
    "                norm_znew += torch.norm(trial)**2\n",
    "            norm_znew = (norm_znew ** 0.5).data.item()\n",
    "\n",
    "            if norm_znew >= radius:\n",
    "                tau = self._findroots(z, d, radius)\n",
    "                for idx in range(len(self.x)):\n",
    "                    d[idx] = z[idx] + tau * d[idx] + 0.0\n",
    "                self.cgflag = 'posbd'\n",
    "                break\n",
    "            rnew = []\n",
    "            norm_rnew = 0.0\n",
    "            for idx in range(len(self.x)):\n",
    "                temp = r[idx] + alpha * Hd[idx] + 0.0\n",
    "                rnew.append(temp)\n",
    "                norm_rnew += torch.norm(temp)**2\n",
    "            norm_rnew = norm_rnew**0.5.data.item()\n",
    "            if norm_rnew < cg_tol:\n",
    "                d = znew\n",
    "                self.cgflag = 'cgtol'\n",
    "            beta = (norm_rnew**2 / norm_r_sq).data.item()\n",
    "            for idx in range(len(self.x)):\n",
    "                d[idx] = -rnew[idx] + beta * d[idx]\n",
    "        return d\n",
    "\n",
    "    def _findroots(self, z, d, radius):\n",
    "        a, b, c = 0.0, 0.0, 0.0\n",
    "        for idx in range(len(z)):\n",
    "            a += (d[idx] * d[idx]).sum()\n",
    "            b += (d[idx] * z[idx]).sum()\n",
    "            c += (z[idx] * d[idx]).sum()\n",
    "        b *= 2.0\n",
    "        c -= radius**2\n",
    "        tau = (-2.0 * c) / (b + (b**2 - (4.0 * a * c))**0.5)\n",
    "        return tau.data.item()\n",
    "\n",
    "    def step(self, loss_fn, aCs, aSs, layers, style_layer_weights,\n",
    "             c_layer, alpha, beta):\n",
    "        \"\"\"\n",
    "            customized step\n",
    "            loss_fn: callable\n",
    "            aCs, aSs, style_layer_weights, c_layer, alpha, beta: function parameters\n",
    "        \"\"\"\n",
    "        aGs = utils.get_feature_maps(self.x[0], layers)\n",
    "        loss, content_cost, style_cost = loss_fn(aGs, aCs, aSs, style_layer_weights,\n",
    "                                                 content_layer_idx=c_layer, alpha=alpha, beta=beta)\n",
    "        print(f'loss:{loss.data.cpu().item():2.3e} | content: {content_cost.item():2.3e} | style_cost:{style_cost.item():2.3e}', flush=True)\n",
    "        gradf = torch.autograd.grad(loss, self.x, create_graph=True)\n",
    "        print(gradf[0].element_size() * gradf[0].nelement()/1e9)\n",
    "        p = self._steihaug(gradf, self.radius)\n",
    "        print(f'   CG-Steihaug: current gradf_norm:{self.norm_gradf0:3.3e} | {self.cg_iter}/{self.cgmaxiter} | terminate with: {self.cgflag}')\n",
    "        # actual decrease at the trial point\n",
    "        with torch.no_grad():\n",
    "            xtrial = []\n",
    "            for idx in range(len(self.x)):\n",
    "                xtrial.append(self.x[idx] + p[idx] + 0.0)\n",
    "        aGnews = utils.get_feature_maps(xtrial[0], layers)\n",
    "        with torch.no_grad():\n",
    "            loss_new, _, _ = loss_fn(aGnews, aCs, aSs, style_layer_weights,\n",
    "                                     content_layer_idx=c_layer, alpha=alpha, beta=beta)\n",
    "        actual_decrease = loss - loss_new\n",
    "        # model decrease at the trial point\n",
    "        Hp = torch.autograd.grad(gradf, self.x, p)\n",
    "        ptHp = 0.0\n",
    "        for idx, hp in enumerate(Hp):\n",
    "            ptHp += (hp * p[idx]).sum()\n",
    "        gp = 0.0\n",
    "        for idx, e in enumerate(gradf):\n",
    "            gp += (e.data * p[idx]).sum()\n",
    "        model_decrease = -gp.data.item() - (ptHp.data.item()) / 2\n",
    "        rho = actual_decrease / model_decrease\n",
    "        norm_p = 0.0\n",
    "        for e in p:\n",
    "            norm_p += torch.norm(e)**2\n",
    "        norm_p = (norm_p ** 0.5).data.item()\n",
    "        if rho < 1 / 4:\n",
    "            self.radius *= 0.25\n",
    "            radius_flag = 'shrink'\n",
    "        else:\n",
    "            if rho > 3 / 4 and np.abs(norm_p - self.radius) <= 1e-10:\n",
    "                self.radius = min(2 * self.radius, self.radius_max)\n",
    "                radius_flag = 'enlarge'\n",
    "            else:\n",
    "                radius_flag = 'unchanged'\n",
    "        if rho > self.eta:\n",
    "            for idx, e in enumerate(self.x):\n",
    "                e.data = e.data + p[idx].data\n",
    "                update_flag = 'move'\n",
    "        else:\n",
    "            update_flag = 'stay'\n",
    "        print(f'   Trust-Region: {radius_flag:10s} | new radius:{self.radius:3.3e} | x-update:{update_flag}')\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "            just \n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:2.625e+02 | content: 0.000e+00 | style_cost:2.625e-02\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 394.00 MiB (GPU 0; 14.76 GiB total capacity; 13.27 GiB already allocated; 379.44 MiB free; 13.54 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1248ab5fd368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarting\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     optimizer.step(utils.compute_total_cost, aCs, aSs, layers, style_layer_weights,\n\u001b[0m\u001b[1;32m      9\u001b[0m              c_layer, alpha, beta)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-7fdabc198259>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, loss_fn, aCs, aSs, layers, style_layer_weights, c_layer, alpha, beta)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                                  content_layer_idx=c_layer, alpha=alpha, beta=beta)\n\u001b[1;32m    139\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'loss:{loss.data.cpu().item():2.3e} | content: {content_cost.item():2.3e} | style_cost:{style_cost.item():2.3e}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mgradf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steihaug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         inputs, allow_unused)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 394.00 MiB (GPU 0; 14.76 GiB total capacity; 13.27 GiB already allocated; 379.44 MiB free; 13.54 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# import gc\n",
    "# del optimizer\n",
    "gc.collect()  \n",
    "torch.cuda.empty_cache()\n",
    "optimizer = TrusRegionCG([G], radius_init=0.1, radius_max=10, eta=0.2)\n",
    "for it in range(starting, starting + epochs):\n",
    "    optimizer.zero_grad()\n",
    "    optimizer.step(utils.compute_total_cost, aCs, aSs, layers, style_layer_weights,\n",
    "             c_layer, alpha, beta)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.norm(optimizer.x[0] - G)\n",
    "optimizer.x[0].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May  5 00:24:56 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.118.02   Driver Version: 440.118.02   CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    25W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            Off  | 00000000:D9:00.0 Off |                    0 |\n",
      "| N/A   24C    P0    20W /  70W |      0MiB / 15109MiB |      5%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kill -9 2409533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
