{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "sys.path.append('../') # append root directory\n",
    "import os\n",
    "import argparse\n",
    "from utils import getLogger\n",
    "from models import ResNet18_wby16\n",
    "from config import Config\n",
    "from admm.warmup_scheduler import GradualWarmupScheduler\n",
    "from admm.cross_entropy import CrossEntropyLossMaybeSmooth\n",
    "from admm.utils import mixup_data, mixup_criterion\n",
    "import admm\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from numpy import linalg as LA\n",
    "import admm\n",
    "import numpy as np\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "def validate(val_loader, criterion, config):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    config.model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            # compute output\n",
    "            output = config.model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(acc1[0], input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % config.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      .format(\n",
    "                          i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                          top1=top1))\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f} '\n",
    "              .format(top1=top1))\n",
    "\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "class AttackPGD(torch.nn.Module):\n",
    "    def __init__(self, basic_model, config):\n",
    "        super(AttackPGD, self).__init__()\n",
    "        self.basic_model = basic_model\n",
    "        self.rand = config.random_start\n",
    "        self.step_size = config.step_size / 255\n",
    "        self.epsilon = config.epsilon / 255\n",
    "        self.num_steps = config.num_steps\n",
    "        print(f\"PGD: step_size:{self.step_size} | epsilon:{self.epsilon} | num_steps:{self.num_steps}\")\n",
    "    def forward(self, input, target):    # do forward in the module.py\n",
    "        # if not args.attack :\n",
    "        #    return self.basic_model(input), input\n",
    "\n",
    "        x = input.detach()\n",
    "\n",
    "        if self.rand:\n",
    "            x = x + torch.zeros_like(x).uniform_(-self.epsilon, self.epsilon)\n",
    "        for i in range(self.num_steps):\n",
    "            x.requires_grad_()\n",
    "            with torch.enable_grad():\n",
    "                logits = self.basic_model(x)\n",
    "                loss = F.cross_entropy(logits, target, size_average=False)\n",
    "            grad = torch.autograd.grad(loss, [x])[0]\n",
    "            x = x.detach() + self.step_size * torch.sign(grad.detach())\n",
    "            x = torch.min(torch.max(x, input - self.epsilon), input + self.epsilon)\n",
    "\n",
    "            x = torch.clamp(x, 0, 1)\n",
    "\n",
    "        return self.basic_model(input), self.basic_model(x), x\n",
    "\n",
    "def validate_adv(val_loader, criterion, config):\n",
    "    batch_time = AverageMeter()\n",
    "    nat_losses = AverageMeter()\n",
    "    adv_losses = AverageMeter()\n",
    "    nat_top1 = AverageMeter()\n",
    "    adv_top1 = AverageMeter()\n",
    "    nat_loss = 0\n",
    "    adv_loss = 0\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    config.model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            # compute output\n",
    "            nat_output, adv_output, pert_inputs = config.model(input, target)\n",
    "            nat_loss = criterion(nat_output, target)\n",
    "            adv_loss = criterion(adv_output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            nat_acc1, nat_acc5 = accuracy(nat_output, target, topk=(1, 5))\n",
    "            adv_acc1, adv_acc5 = accuracy(adv_output, target, topk=(1, 5))\n",
    "            nat_losses.update(nat_loss.item(), input.size(0))\n",
    "            adv_losses.update(adv_loss.item(), input.size(0))\n",
    "            nat_top1.update(nat_acc1[0], input.size(0))\n",
    "            adv_top1.update(adv_acc1[0], input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % config.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Nat_Loss {nat_loss.val:.4f} ({nat_loss.avg:.4f})\\t'\n",
    "                      'Nat_Acc@1 {nat_top1.val:.3f} ({nat_top1.avg:.3f})\\t'\n",
    "                      'Adv_Loss {adv_loss.val:.4f} ({adv_loss.avg:.4f})\\t'\n",
    "                      'Adv_Acc@1 {adv_top1.val:.3f} ({adv_top1.avg:.3f})\\t'\n",
    "                      .format(\n",
    "                          i, len(val_loader), batch_time=batch_time, nat_loss=nat_losses,\n",
    "                          nat_top1=nat_top1, adv_loss=adv_losses, adv_top1=adv_top1))\n",
    "\n",
    "        print(' * Nat_Acc@1 {nat_top1.avg:.3f} *Adv_Acc@1 {adv_top1.avg:.3f}'\n",
    "              .format(nat_top1=nat_top1, adv_top1=adv_top1))\n",
    "\n",
    "    return adv_top1.avg\n",
    "\n",
    "criterion = CrossEntropyLossMaybeSmooth(smooth_eps=0.0).cuda()\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=16)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naturally trained resnet18 with w=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "==> Loading from ./trainedMod/resnet18_16by16_pretrained.pt\n",
      "==> Adversarial Accuracy..\n",
      "PGD: step_size:0.00784313725490196 | epsilon:0.03137254901960784 | num_steps:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yud319/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/100]\tTime 4.048 (4.048)\tNat_Loss 0.3306 (0.3306)\tNat_Acc@1 95.000 (95.000)\tAdv_Loss 18.2532 (18.2532)\tAdv_Acc@1 17.000 (17.000)\t\n",
      "Test: [10/100]\tTime 0.501 (0.821)\tNat_Loss 0.1819 (0.5375)\tNat_Acc@1 97.000 (93.455)\tAdv_Loss 17.3895 (18.5189)\tAdv_Acc@1 19.000 (15.273)\t\n",
      "Test: [20/100]\tTime 0.498 (0.668)\tNat_Loss 0.7931 (0.5728)\tNat_Acc@1 93.000 (93.143)\tAdv_Loss 18.2467 (18.6935)\tAdv_Acc@1 20.000 (14.714)\t\n",
      "Test: [30/100]\tTime 0.500 (0.613)\tNat_Loss 0.5674 (0.6170)\tNat_Acc@1 92.000 (93.097)\tAdv_Loss 17.9494 (18.6740)\tAdv_Acc@1 14.000 (14.516)\t\n",
      "Test: [40/100]\tTime 0.501 (0.586)\tNat_Loss 1.0210 (0.6508)\tNat_Acc@1 90.000 (92.659)\tAdv_Loss 21.2271 (18.8756)\tAdv_Acc@1 17.000 (14.829)\t\n",
      "Test: [50/100]\tTime 0.501 (0.569)\tNat_Loss 0.2226 (0.6480)\tNat_Acc@1 96.000 (92.843)\tAdv_Loss 18.9179 (18.6796)\tAdv_Acc@1 13.000 (15.137)\t\n",
      "Test: [60/100]\tTime 0.501 (0.558)\tNat_Loss 0.4355 (0.6285)\tNat_Acc@1 95.000 (93.049)\tAdv_Loss 18.6501 (18.6832)\tAdv_Acc@1 18.000 (14.951)\t\n",
      "Test: [70/100]\tTime 0.502 (0.550)\tNat_Loss 1.2535 (0.6035)\tNat_Acc@1 88.000 (93.239)\tAdv_Loss 18.9969 (18.6384)\tAdv_Acc@1 18.000 (14.845)\t\n",
      "Test: [80/100]\tTime 0.501 (0.544)\tNat_Loss 0.4119 (0.6038)\tNat_Acc@1 95.000 (93.222)\tAdv_Loss 19.8888 (18.6460)\tAdv_Acc@1 16.000 (14.802)\t\n",
      "Test: [90/100]\tTime 0.502 (0.539)\tNat_Loss 0.5485 (0.5946)\tNat_Acc@1 93.000 (93.253)\tAdv_Loss 18.1804 (18.6492)\tAdv_Acc@1 19.000 (14.956)\t\n",
      " * Nat_Acc@1 93.240 *Adv_Acc@1 15.020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(15.0200, device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "parser.add_argument('--config_file', type=str, default='./prune/config_w16to8.yaml', help =\"config file\")\n",
    "parser.add_argument('--stage', type=str, default='admm', help =\"select the pruning stage\")\n",
    "args = parser.parse_args(\"\")\n",
    "config = Config(args)\n",
    "\n",
    "print('==> Building model..')\n",
    "model = ResNet18_wby16(config.w)\n",
    "config.model = model\n",
    "\n",
    "if device == 'cuda':\n",
    "    if config.gpu is not None:\n",
    "        torch.cuda.set_device(config.gpu)\n",
    "        config.model = torch.nn.DataParallel(model, device_ids=[config.gpu])\n",
    "    else:\n",
    "        config.model.cuda()\n",
    "        config.model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if config.load_model:\n",
    "    # unlike resume, load model does not care optimizer status or start_epoch\n",
    "    if config.stage == 'admm':\n",
    "        config.load_model = config.load_model.replace('w', str(config.w))\n",
    "    else:\n",
    "        config.load_model = config.load_model.replace('w', str(config.w))\n",
    "        prune_alpha = config._prune_ratios['conv1.weight']\n",
    "        config.load_model = f\"{config.load_model.split('.pt')[0]}_{prune_alpha}.pt\"\n",
    "        config.save_model = f\"{config.save_model.split('.pt')[0]}_{prune_alpha}.pt\"\n",
    "    print('==> Loading from {}'.format(config.load_model))\n",
    "\n",
    "    config.model.load_state_dict(torch.load(config.load_model))  # i call 'net' \"model\"\n",
    "print('==> Adversarial Accuracy..')\n",
    "config.model =  AttackPGD(config.model, config)\n",
    "validate_adv(testloader, criterion, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naturally trained resnet18 with w=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "==> Loading from ./trainedMod/resnet18_8by16_pretrained.pt\n",
      "==> Adversarial Accuracy..\n",
      "PGD: step_size:0.00784313725490196 | epsilon:0.03137254901960784 | num_steps:10\n",
      "Test: [0/100]\tTime 1.154 (1.154)\tNat_Loss 0.4664 (0.4664)\tNat_Acc@1 93.000 (93.000)\tAdv_Loss 17.9320 (17.9320)\tAdv_Acc@1 16.000 (16.000)\t\n",
      "Test: [10/100]\tTime 0.207 (0.278)\tNat_Loss 0.7127 (0.4825)\tNat_Acc@1 95.000 (93.000)\tAdv_Loss 18.4954 (20.3697)\tAdv_Acc@1 14.000 (12.182)\t\n",
      "Test: [20/100]\tTime 0.187 (0.235)\tNat_Loss 1.3370 (0.6512)\tNat_Acc@1 85.000 (91.524)\tAdv_Loss 20.9146 (20.6679)\tAdv_Acc@1 14.000 (11.190)\t\n",
      "Test: [30/100]\tTime 0.187 (0.219)\tNat_Loss 0.5593 (0.6837)\tNat_Acc@1 90.000 (91.419)\tAdv_Loss 19.6131 (20.5044)\tAdv_Acc@1 12.000 (11.032)\t\n",
      "Test: [40/100]\tTime 0.188 (0.212)\tNat_Loss 1.1814 (0.7059)\tNat_Acc@1 88.000 (91.463)\tAdv_Loss 23.3852 (20.7484)\tAdv_Acc@1 8.000 (11.024)\t\n",
      "Test: [50/100]\tTime 0.189 (0.207)\tNat_Loss 0.4618 (0.6872)\tNat_Acc@1 92.000 (91.510)\tAdv_Loss 21.4839 (20.6831)\tAdv_Acc@1 13.000 (11.216)\t\n",
      "Test: [60/100]\tTime 0.188 (0.204)\tNat_Loss 0.3025 (0.6902)\tNat_Acc@1 93.000 (91.508)\tAdv_Loss 19.8527 (20.6884)\tAdv_Acc@1 10.000 (11.049)\t\n",
      "Test: [70/100]\tTime 0.189 (0.202)\tNat_Loss 1.3600 (0.6793)\tNat_Acc@1 90.000 (91.690)\tAdv_Loss 23.1238 (20.6181)\tAdv_Acc@1 10.000 (11.028)\t\n",
      "Test: [80/100]\tTime 0.188 (0.200)\tNat_Loss 0.5433 (0.6829)\tNat_Acc@1 92.000 (91.679)\tAdv_Loss 19.8426 (20.6430)\tAdv_Acc@1 11.000 (10.926)\t\n",
      "Test: [90/100]\tTime 0.188 (0.199)\tNat_Loss 0.3337 (0.6682)\tNat_Acc@1 95.000 (91.846)\tAdv_Loss 21.8654 (20.6454)\tAdv_Acc@1 9.000 (10.945)\t\n",
      " * Nat_Acc@1 91.790 *Adv_Acc@1 10.800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(10.8000, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 8\n",
    "print('==> Building model..')\n",
    "model = ResNet18_wby16(w)\n",
    "config.model = model\n",
    "\n",
    "config.model.cuda()\n",
    "config.model = torch.nn.DataParallel(model)\n",
    "cudnn.benchmark = True\n",
    "config.load_model = f'./trainedMod/resnet18_{w}by16_pretrained.pt'\n",
    "print('==> Loading from {}'.format(config.load_model))\n",
    "config.model.load_state_dict(torch.load(config.load_model))  \n",
    "print('==> Adversarial Accuracy..')\n",
    "config.model =  AttackPGD(config.model, config)\n",
    "validate_adv(testloader, criterion, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naturally trained resnet18 with w=16 and prune to 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "==> Loading from ./trainedMod/resnet18_16by16_retrained_0.5.pt\n",
      "==> Adversarial Accuracy..\n",
      "PGD: step_size:0.00784313725490196 | epsilon:0.03137254901960784 | num_steps:10\n",
      "Test: [0/100]\tTime 1.283 (1.283)\tNat_Loss 0.1662 (0.1662)\tNat_Acc@1 97.000 (97.000)\tAdv_Loss 18.9075 (18.9075)\tAdv_Acc@1 17.000 (17.000)\t\n",
      "Test: [10/100]\tTime 0.496 (0.567)\tNat_Loss 0.2888 (0.5162)\tNat_Acc@1 96.000 (93.455)\tAdv_Loss 18.8089 (19.3458)\tAdv_Acc@1 14.000 (13.091)\t\n",
      "Test: [20/100]\tTime 0.494 (0.533)\tNat_Loss 0.4950 (0.5747)\tNat_Acc@1 92.000 (92.810)\tAdv_Loss 19.1343 (19.6161)\tAdv_Acc@1 15.000 (12.333)\t\n",
      "Test: [30/100]\tTime 0.496 (0.521)\tNat_Loss 0.5773 (0.6116)\tNat_Acc@1 92.000 (92.548)\tAdv_Loss 19.4043 (19.6198)\tAdv_Acc@1 12.000 (12.032)\t\n",
      "Test: [40/100]\tTime 0.496 (0.515)\tNat_Loss 0.9862 (0.6497)\tNat_Acc@1 88.000 (92.171)\tAdv_Loss 21.9048 (19.7843)\tAdv_Acc@1 9.000 (11.878)\t\n",
      "Test: [50/100]\tTime 0.497 (0.511)\tNat_Loss 0.2701 (0.6550)\tNat_Acc@1 96.000 (92.353)\tAdv_Loss 19.9243 (19.5861)\tAdv_Acc@1 12.000 (12.078)\t\n",
      "Test: [60/100]\tTime 0.498 (0.509)\tNat_Loss 0.4309 (0.6346)\tNat_Acc@1 95.000 (92.459)\tAdv_Loss 19.8394 (19.6150)\tAdv_Acc@1 15.000 (11.984)\t\n",
      "Test: [70/100]\tTime 0.498 (0.507)\tNat_Loss 1.1454 (0.6281)\tNat_Acc@1 90.000 (92.408)\tAdv_Loss 19.6288 (19.5213)\tAdv_Acc@1 12.000 (11.930)\t\n",
      "Test: [80/100]\tTime 0.498 (0.506)\tNat_Loss 0.1850 (0.6222)\tNat_Acc@1 96.000 (92.605)\tAdv_Loss 21.3367 (19.5957)\tAdv_Acc@1 11.000 (11.840)\t\n",
      "Test: [90/100]\tTime 0.498 (0.505)\tNat_Loss 0.3843 (0.6194)\tNat_Acc@1 97.000 (92.626)\tAdv_Loss 19.5635 (19.6111)\tAdv_Acc@1 12.000 (11.868)\t\n",
      " * Nat_Acc@1 92.690 *Adv_Acc@1 11.920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(11.9200, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 16\n",
    "print('==> Building model..')\n",
    "model = ResNet18_wby16(w)\n",
    "config.model = model\n",
    "\n",
    "config.model.cuda()\n",
    "config.model = torch.nn.DataParallel(model)\n",
    "cudnn.benchmark = True\n",
    "config.load_model = f'./trainedMod/resnet18_{w}by16_retrained_0.5.pt'\n",
    "print('==> Loading from {}'.format(config.load_model))\n",
    "config.model.load_state_dict(torch.load(config.load_model))  \n",
    "print('==> Adversarial Accuracy..')\n",
    "config.model =  AttackPGD(config.model, config)\n",
    "validate_adv(testloader, criterion, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sparsity(config):\n",
    "    \"\"\"\n",
    "    test sparsity for every involved layer and the overall compression rate\n",
    "\n",
    "    \"\"\"\n",
    "    total_zeros = 0\n",
    "    total_nonzeros = 0\n",
    "\n",
    "    print('<===sparsity type is {}'.format(config.sparsity_type))\n",
    "    print('<===layers to be pruned are \\n{}'.format(config._prune_ratios))\n",
    "    if config.sparsity_type == \"irregular\":\n",
    "        for name, W in config.model.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                continue\n",
    "            W = W.cpu().detach().numpy()\n",
    "            zeros = np.sum(W == 0)\n",
    "            total_zeros += zeros\n",
    "            nonzeros = np.sum(W != 0)\n",
    "            total_nonzeros += nonzeros\n",
    "            print(\"sparsity at layer {} is {}\".format(name, zeros / (zeros + nonzeros)))\n",
    "        total_weight_number = total_zeros + total_nonzeros\n",
    "        print('overal compression rate is {}'.format(total_weight_number / total_nonzeros))\n",
    "    elif config.sparsity_type == \"filter\":\n",
    "        print('inside if')\n",
    "        print(config.prune_ratios)\n",
    "        for name, W in config.model.named_parameters():\n",
    "            if name not in config.prune_ratios:\n",
    "                continue\n",
    "            W = W.cpu().detach().numpy()\n",
    "            shape = W.shape\n",
    "            W2d = W.reshape(shape[0], -1)\n",
    "            row_l2_norm = LA.norm(W2d, 2, axis=1)\n",
    "            zero_row = np.sum(row_l2_norm == 0)\n",
    "            nonzero_row = np.sum(row_l2_norm != 0)\n",
    "            total_zeros += np.sum(W == 0)\n",
    "            total_nonzeros += np.sum(W != 0)\n",
    "            print(\"filter sparsity of layer {} is {}\".format(name, zero_row / (zero_row + nonzero_row)))\n",
    "        print('only consider conv layers, compression rate is {}'.format((total_zeros + total_nonzeros) / total_nonzeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'basic_model', 'basic_model.module', 'basic_model.module.conv1', 'basic_model.module.bn1', 'basic_model.module.layer1', 'basic_model.module.layer1.0', 'basic_model.module.layer1.0.conv1', 'basic_model.module.layer1.0.bn1', 'basic_model.module.layer1.0.conv2', 'basic_model.module.layer1.0.bn2', 'basic_model.module.layer1.0.shortcut', 'basic_model.module.layer1.1', 'basic_model.module.layer1.1.conv1', 'basic_model.module.layer1.1.bn1', 'basic_model.module.layer1.1.conv2', 'basic_model.module.layer1.1.bn2', 'basic_model.module.layer1.1.shortcut', 'basic_model.module.layer2', 'basic_model.module.layer2.0', 'basic_model.module.layer2.0.conv1', 'basic_model.module.layer2.0.bn1', 'basic_model.module.layer2.0.conv2', 'basic_model.module.layer2.0.bn2', 'basic_model.module.layer2.0.shortcut', 'basic_model.module.layer2.0.shortcut.0', 'basic_model.module.layer2.0.shortcut.1', 'basic_model.module.layer2.1', 'basic_model.module.layer2.1.conv1', 'basic_model.module.layer2.1.bn1', 'basic_model.module.layer2.1.conv2', 'basic_model.module.layer2.1.bn2', 'basic_model.module.layer2.1.shortcut', 'basic_model.module.layer3', 'basic_model.module.layer3.0', 'basic_model.module.layer3.0.conv1', 'basic_model.module.layer3.0.bn1', 'basic_model.module.layer3.0.conv2', 'basic_model.module.layer3.0.bn2', 'basic_model.module.layer3.0.shortcut', 'basic_model.module.layer3.0.shortcut.0', 'basic_model.module.layer3.0.shortcut.1', 'basic_model.module.layer3.1', 'basic_model.module.layer3.1.conv1', 'basic_model.module.layer3.1.bn1', 'basic_model.module.layer3.1.conv2', 'basic_model.module.layer3.1.bn2', 'basic_model.module.layer3.1.shortcut', 'basic_model.module.layer4', 'basic_model.module.layer4.0', 'basic_model.module.layer4.0.conv1', 'basic_model.module.layer4.0.bn1', 'basic_model.module.layer4.0.conv2', 'basic_model.module.layer4.0.bn2', 'basic_model.module.layer4.0.shortcut', 'basic_model.module.layer4.0.shortcut.0', 'basic_model.module.layer4.0.shortcut.1', 'basic_model.module.layer4.1', 'basic_model.module.layer4.1.conv1', 'basic_model.module.layer4.1.bn1', 'basic_model.module.layer4.1.conv2', 'basic_model.module.layer4.1.bn2', 'basic_model.module.layer4.1.shortcut', 'basic_model.module.linear']\n",
      "<===sparsity type is filter\n",
      "<===layers to be pruned are \n",
      "{'conv1.weight': 0.5, 'conv2.weight': 0.5, 'conv3.weight': 0.5, 'conv4.weight': 0.5, 'conv5.weight': 0.5, 'conv6.weight': 0.5, 'conv7.weight': 0.5, 'conv8.weight': 0.5, 'conv9.weight': 0.5, 'conv10.weight': 0.5, 'conv11.weight': 0.5, 'conv12.weight': 0.5, 'conv13.weight': 0.5, 'conv14.weight': 0.5, 'conv15.weight': 0.5, 'conv16.weight': 0.5, 'conv17.weight': 0.5, 'conv18.weight': 0.5, 'conv19.weight': 0.5, 'conv20.weight': 0.5}\n",
      "inside if\n",
      "{'basic_model.module.conv1.weight': 0.5, 'basic_model.module.layer1.0.conv1.weight': 0.5, 'basic_model.module.layer1.0.conv2.weight': 0.5, 'basic_model.module.layer1.1.conv1.weight': 0.5, 'basic_model.module.layer1.1.conv2.weight': 0.5, 'basic_model.module.layer2.0.conv1.weight': 0.5, 'basic_model.module.layer2.0.conv2.weight': 0.5, 'basic_model.module.layer2.0.shortcut.0.weight': 0.5, 'basic_model.module.layer2.1.conv1.weight': 0.5, 'basic_model.module.layer2.1.conv2.weight': 0.5, 'basic_model.module.layer3.0.conv1.weight': 0.5, 'basic_model.module.layer3.0.conv2.weight': 0.5, 'basic_model.module.layer3.0.shortcut.0.weight': 0.5, 'basic_model.module.layer3.1.conv1.weight': 0.5, 'basic_model.module.layer3.1.conv2.weight': 0.5, 'basic_model.module.layer4.0.conv1.weight': 0.5, 'basic_model.module.layer4.0.conv2.weight': 0.5, 'basic_model.module.layer4.0.shortcut.0.weight': 0.5, 'basic_model.module.layer4.1.conv1.weight': 0.5, 'basic_model.module.layer4.1.conv2.weight': 0.5}\n",
      "filter sparsity of layer basic_model.module.conv1.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer1.0.conv1.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer1.0.conv2.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer1.1.conv1.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer1.1.conv2.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer2.0.conv1.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer2.0.conv2.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer2.0.shortcut.0.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer2.1.conv1.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer2.1.conv2.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer3.0.conv1.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer3.0.conv2.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer3.0.shortcut.0.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer3.1.conv1.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer3.1.conv2.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer4.0.conv1.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer4.0.conv2.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer4.0.shortcut.0.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer4.1.conv1.weight is 0.5\n",
      "filter sparsity of layer basic_model.module.layer4.1.conv2.weight is 0.5\n",
      "only consider conv layers, compression rate is 2.0\n"
     ]
    }
   ],
   "source": [
    "config.prepare_pruning() \n",
    "ADMM = admm.ADMM(config, device)\n",
    "test_sparsity(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naturally trained resnet18 with w=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "==> Loading from ./trainedMod/resnet18_1by16_pretrained.pt\n",
      "==> Adversarial Accuracy..\n",
      "PGD: step_size:0.00784313725490196 | epsilon:0.03137254901960784 | num_steps:10\n",
      "Test: [0/100]\tTime 0.920 (0.920)\tNat_Loss 0.9712 (0.9712)\tNat_Acc@1 70.000 (70.000)\tAdv_Loss 4.7230 (4.7230)\tAdv_Acc@1 6.000 (6.000)\t\n",
      "Test: [10/100]\tTime 0.137 (0.210)\tNat_Loss 0.6861 (0.8973)\tNat_Acc@1 78.000 (70.273)\tAdv_Loss 4.3154 (4.8665)\tAdv_Acc@1 7.000 (6.182)\t\n",
      "Test: [20/100]\tTime 0.137 (0.175)\tNat_Loss 0.9934 (0.8936)\tNat_Acc@1 71.000 (70.333)\tAdv_Loss 4.8932 (4.9534)\tAdv_Acc@1 11.000 (6.524)\t\n",
      "Test: [30/100]\tTime 0.137 (0.164)\tNat_Loss 0.8345 (0.9065)\tNat_Acc@1 75.000 (70.387)\tAdv_Loss 5.3006 (4.9888)\tAdv_Acc@1 5.000 (6.613)\t\n",
      "Test: [40/100]\tTime 0.137 (0.158)\tNat_Loss 1.0701 (0.9153)\tNat_Acc@1 71.000 (70.073)\tAdv_Loss 5.1748 (5.0502)\tAdv_Acc@1 9.000 (6.780)\t\n",
      "Test: [50/100]\tTime 0.139 (0.154)\tNat_Loss 0.9353 (0.9031)\tNat_Acc@1 71.000 (70.627)\tAdv_Loss 5.4839 (5.0262)\tAdv_Acc@1 5.000 (6.804)\t\n",
      "Test: [60/100]\tTime 0.138 (0.152)\tNat_Loss 0.9316 (0.9158)\tNat_Acc@1 70.000 (70.098)\tAdv_Loss 4.6785 (5.0268)\tAdv_Acc@1 16.000 (6.525)\t\n",
      "Test: [70/100]\tTime 0.137 (0.150)\tNat_Loss 0.8657 (0.9142)\tNat_Acc@1 73.000 (69.915)\tAdv_Loss 5.2715 (5.0306)\tAdv_Acc@1 7.000 (6.620)\t\n",
      "Test: [80/100]\tTime 0.137 (0.148)\tNat_Loss 0.8719 (0.9080)\tNat_Acc@1 69.000 (69.877)\tAdv_Loss 5.8894 (5.0407)\tAdv_Acc@1 9.000 (6.568)\t\n",
      "Test: [90/100]\tTime 0.165 (0.147)\tNat_Loss 0.8382 (0.9085)\tNat_Acc@1 68.000 (69.747)\tAdv_Loss 4.7372 (5.0453)\tAdv_Acc@1 5.000 (6.725)\t\n",
      " * Nat_Acc@1 70.080 *Adv_Acc@1 6.750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.7500, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 1\n",
    "print('==> Building model..')\n",
    "model = ResNet18_wby16(w)\n",
    "config.model = model\n",
    "\n",
    "config.model.cuda()\n",
    "config.model = torch.nn.DataParallel(model)\n",
    "cudnn.benchmark = True\n",
    "config.load_model = f'./trainedMod/resnet18_{w}by16_pretrained.pt'\n",
    "print('==> Loading from {}'.format(config.load_model))\n",
    "config.model.load_state_dict(torch.load(config.load_model))  \n",
    "print('==> Adversarial Accuracy..')\n",
    "config.model =  AttackPGD(config.model, config)\n",
    "validate_adv(testloader, criterion, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naturally trained resnet18 with w=16 and prune to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "==> Building model..\n",
      "==> Loading from ./trainedMod/resnet18_16by16_retrained_0.9375.pt\n",
      "==> Adversarial Accuracy..\n",
      "PGD: step_size:0.00784313725490196 | epsilon:0.03137254901960784 | num_steps:10\n",
      "Test: [0/100]\tTime 1.286 (1.286)\tNat_Loss 1.1525 (1.1525)\tNat_Acc@1 61.000 (61.000)\tAdv_Loss 3.4195 (3.4195)\tAdv_Acc@1 8.000 (8.000)\t\n",
      "Test: [10/100]\tTime 0.488 (0.561)\tNat_Loss 1.2681 (1.2239)\tNat_Acc@1 52.000 (55.818)\tAdv_Loss 3.3332 (3.6798)\tAdv_Acc@1 9.000 (7.545)\t\n",
      "Test: [20/100]\tTime 0.488 (0.527)\tNat_Loss 1.4683 (1.2567)\tNat_Acc@1 49.000 (55.095)\tAdv_Loss 3.7568 (3.7610)\tAdv_Acc@1 8.000 (7.381)\t\n",
      "Test: [30/100]\tTime 0.488 (0.515)\tNat_Loss 1.0839 (1.2597)\tNat_Acc@1 62.000 (54.645)\tAdv_Loss 3.7214 (3.7729)\tAdv_Acc@1 5.000 (7.742)\t\n",
      "Test: [40/100]\tTime 0.489 (0.508)\tNat_Loss 1.2460 (1.2645)\tNat_Acc@1 56.000 (55.000)\tAdv_Loss 3.9271 (3.8231)\tAdv_Acc@1 7.000 (7.585)\t\n",
      "Test: [50/100]\tTime 0.490 (0.505)\tNat_Loss 1.3535 (1.2560)\tNat_Acc@1 53.000 (55.216)\tAdv_Loss 3.9928 (3.8187)\tAdv_Acc@1 6.000 (7.471)\t\n",
      "Test: [60/100]\tTime 0.491 (0.502)\tNat_Loss 1.4108 (1.2633)\tNat_Acc@1 50.000 (55.016)\tAdv_Loss 3.4282 (3.8137)\tAdv_Acc@1 8.000 (7.098)\t\n",
      "Test: [70/100]\tTime 0.491 (0.501)\tNat_Loss 1.3419 (1.2654)\tNat_Acc@1 47.000 (55.056)\tAdv_Loss 4.0487 (3.8050)\tAdv_Acc@1 11.000 (7.127)\t\n",
      "Test: [80/100]\tTime 0.492 (0.500)\tNat_Loss 1.1193 (1.2602)\tNat_Acc@1 53.000 (54.840)\tAdv_Loss 4.2091 (3.8124)\tAdv_Acc@1 9.000 (7.074)\t\n",
      "Test: [90/100]\tTime 0.491 (0.499)\tNat_Loss 1.3003 (1.2602)\tNat_Acc@1 49.000 (54.593)\tAdv_Loss 3.7089 (3.8095)\tAdv_Acc@1 8.000 (7.044)\t\n",
      " * Nat_Acc@1 54.730 *Adv_Acc@1 7.100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(7.1000, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "parser.add_argument('--config_file', type=str, default='./prune/config_w16to1.yaml', help =\"config file\")\n",
    "parser.add_argument('--stage', type=str, default='admm', help =\"select the pruning stage\")\n",
    "args = parser.parse_args(\"\")\n",
    "config = Config(args)\n",
    "\n",
    "print('==> Building model..')\n",
    "w = 16\n",
    "print('==> Building model..')\n",
    "model = ResNet18_wby16(w)\n",
    "config.model = model\n",
    "\n",
    "config.model.cuda()\n",
    "config.model = torch.nn.DataParallel(model)\n",
    "cudnn.benchmark = True\n",
    "config.load_model = f'./trainedMod/resnet18_{w}by16_retrained_0.9375.pt'\n",
    "print('==> Loading from {}'.format(config.load_model))\n",
    "config.model.load_state_dict(torch.load(config.load_model))  \n",
    "print('==> Adversarial Accuracy..')\n",
    "config.model =  AttackPGD(config.model, config)\n",
    "validate_adv(testloader, criterion, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'basic_model', 'basic_model.module', 'basic_model.module.conv1', 'basic_model.module.bn1', 'basic_model.module.layer1', 'basic_model.module.layer1.0', 'basic_model.module.layer1.0.conv1', 'basic_model.module.layer1.0.bn1', 'basic_model.module.layer1.0.conv2', 'basic_model.module.layer1.0.bn2', 'basic_model.module.layer1.0.shortcut', 'basic_model.module.layer1.1', 'basic_model.module.layer1.1.conv1', 'basic_model.module.layer1.1.bn1', 'basic_model.module.layer1.1.conv2', 'basic_model.module.layer1.1.bn2', 'basic_model.module.layer1.1.shortcut', 'basic_model.module.layer2', 'basic_model.module.layer2.0', 'basic_model.module.layer2.0.conv1', 'basic_model.module.layer2.0.bn1', 'basic_model.module.layer2.0.conv2', 'basic_model.module.layer2.0.bn2', 'basic_model.module.layer2.0.shortcut', 'basic_model.module.layer2.0.shortcut.0', 'basic_model.module.layer2.0.shortcut.1', 'basic_model.module.layer2.1', 'basic_model.module.layer2.1.conv1', 'basic_model.module.layer2.1.bn1', 'basic_model.module.layer2.1.conv2', 'basic_model.module.layer2.1.bn2', 'basic_model.module.layer2.1.shortcut', 'basic_model.module.layer3', 'basic_model.module.layer3.0', 'basic_model.module.layer3.0.conv1', 'basic_model.module.layer3.0.bn1', 'basic_model.module.layer3.0.conv2', 'basic_model.module.layer3.0.bn2', 'basic_model.module.layer3.0.shortcut', 'basic_model.module.layer3.0.shortcut.0', 'basic_model.module.layer3.0.shortcut.1', 'basic_model.module.layer3.1', 'basic_model.module.layer3.1.conv1', 'basic_model.module.layer3.1.bn1', 'basic_model.module.layer3.1.conv2', 'basic_model.module.layer3.1.bn2', 'basic_model.module.layer3.1.shortcut', 'basic_model.module.layer4', 'basic_model.module.layer4.0', 'basic_model.module.layer4.0.conv1', 'basic_model.module.layer4.0.bn1', 'basic_model.module.layer4.0.conv2', 'basic_model.module.layer4.0.bn2', 'basic_model.module.layer4.0.shortcut', 'basic_model.module.layer4.0.shortcut.0', 'basic_model.module.layer4.0.shortcut.1', 'basic_model.module.layer4.1', 'basic_model.module.layer4.1.conv1', 'basic_model.module.layer4.1.bn1', 'basic_model.module.layer4.1.conv2', 'basic_model.module.layer4.1.bn2', 'basic_model.module.layer4.1.shortcut', 'basic_model.module.linear']\n",
      "<===sparsity type is filter\n",
      "<===layers to be pruned are \n",
      "{'conv1.weight': 0.9375, 'conv2.weight': 0.9375, 'conv3.weight': 0.9375, 'conv4.weight': 0.9375, 'conv5.weight': 0.9375, 'conv6.weight': 0.9375, 'conv7.weight': 0.9375, 'conv8.weight': 0.9375, 'conv9.weight': 0.9375, 'conv10.weight': 0.9375, 'conv11.weight': 0.9375, 'conv12.weight': 0.9375, 'conv13.weight': 0.9375, 'conv14.weight': 0.9375, 'conv15.weight': 0.9375, 'conv16.weight': 0.9375, 'conv17.weight': 0.9375, 'conv18.weight': 0.9375, 'conv19.weight': 0.9375, 'conv20.weight': 0.9375}\n",
      "inside if\n",
      "{'basic_model.module.conv1.weight': 0.9375, 'basic_model.module.layer1.0.conv1.weight': 0.9375, 'basic_model.module.layer1.0.conv2.weight': 0.9375, 'basic_model.module.layer1.1.conv1.weight': 0.9375, 'basic_model.module.layer1.1.conv2.weight': 0.9375, 'basic_model.module.layer2.0.conv1.weight': 0.9375, 'basic_model.module.layer2.0.conv2.weight': 0.9375, 'basic_model.module.layer2.0.shortcut.0.weight': 0.9375, 'basic_model.module.layer2.1.conv1.weight': 0.9375, 'basic_model.module.layer2.1.conv2.weight': 0.9375, 'basic_model.module.layer3.0.conv1.weight': 0.9375, 'basic_model.module.layer3.0.conv2.weight': 0.9375, 'basic_model.module.layer3.0.shortcut.0.weight': 0.9375, 'basic_model.module.layer3.1.conv1.weight': 0.9375, 'basic_model.module.layer3.1.conv2.weight': 0.9375, 'basic_model.module.layer4.0.conv1.weight': 0.9375, 'basic_model.module.layer4.0.conv2.weight': 0.9375, 'basic_model.module.layer4.0.shortcut.0.weight': 0.9375, 'basic_model.module.layer4.1.conv1.weight': 0.9375, 'basic_model.module.layer4.1.conv2.weight': 0.9375}\n",
      "filter sparsity of layer basic_model.module.conv1.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer1.0.conv1.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer1.0.conv2.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer1.1.conv1.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer1.1.conv2.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer2.0.conv1.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer2.0.conv2.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer2.0.shortcut.0.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer2.1.conv1.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer2.1.conv2.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer3.0.conv1.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer3.0.conv2.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer3.0.shortcut.0.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer3.1.conv1.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer3.1.conv2.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer4.0.conv1.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer4.0.conv2.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer4.0.shortcut.0.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer4.1.conv1.weight is 0.9375\n",
      "filter sparsity of layer basic_model.module.layer4.1.conv2.weight is 0.9375\n",
      "only consider conv layers, compression rate is 16.000022940679703\n"
     ]
    }
   ],
   "source": [
    "config.prepare_pruning() \n",
    "ADMM = admm.ADMM(config, device)\n",
    "test_sparsity(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
