{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "sys.path.append('../../') # append root directory\n",
    "import os\n",
    "import argparse\n",
    "from cifar10.utils import getLogger\n",
    "from cifar10.models import ResNet18_wby16\n",
    "from cifar10.config import Config\n",
    "from admm.warmup_scheduler import GradualWarmupScheduler\n",
    "from admm.cross_entropy import CrossEntropyLossMaybeSmooth\n",
    "from admm.utils import mixup_data, mixup_criterion\n",
    "import admm\n",
    "import torch.optim as optim\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get configuration\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "parser.add_argument('--config_file', type=str, default='./cifar10/config.yaml', help =\"config file\")\n",
    "parser.add_argument('--stage', type=str, default='admm', help =\"select the pruning stage\")\n",
    "args = parser.parse_args(\"\")\n",
    "config = Config(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('admm', 0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.stage, config.smooth_eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "under stand the mixup data augumentation and mixup loss function\n",
    "https://github.com/facebookresearch/mixup-cifar10/issues/18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yud319/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1607369981906/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "if config.logging:\n",
    "    log_dir = config.log_dir\n",
    "    logger = getLogger(log_dir)\n",
    "    logger.info(json.dumps(config.__dict__, indent=4))\n",
    "else:\n",
    "    logger = None\n",
    "\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=config.workers)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=config.workers)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "==> Loading from resnet18_wby16_pretrained.pt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resnet18_wby16_pretrained.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d6eda8e7f9c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'==> Loading from {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# i call 'net' \"model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resnet18_wby16_pretrained.pt'"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "print('==> Building model..')\n",
    "model = None\n",
    "if config.arch == \"vgg16\":\n",
    "    model = VGG('vgg16', w= config.width_multiplier)\n",
    "elif config.arch ==\"resnet18_wby16\":\n",
    "    model = ResNet18_wby16(config.w)\n",
    "config.model = model\n",
    "\n",
    "if device == 'cuda':\n",
    "    if config.gpu is not None:\n",
    "        torch.cuda.set_device(config.gpu)\n",
    "        config.model = torch.nn.DataParallel(model,device_ids = [config.gpu])\n",
    "    else:\n",
    "        config.model.cuda()\n",
    "        config.model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if config.load_model:\n",
    "    # unlike resume, load model does not care optimizer status or start_epoch\n",
    "    config.load_model.replace('w', str(config.w))\n",
    "    print('==> Loading from {}'.format(config.load_model))\n",
    "\n",
    "    config.model.load_state_dict(torch.load(config.load_model)) # i call 'net' \"model\"\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "config.prepare_pruning() # take the model and prepare the pruning\n",
    "\n",
    "ADMM = None\n",
    "\n",
    "if config.admm:\n",
    "    ADMM = admm.ADMM(config, device)\n",
    "\n",
    "\n",
    "\n",
    "if config.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.t7')\n",
    "    config.model.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    ADMM.ADMM_U = checkpoint['admm']['ADMM_U']\n",
    "    ADMM.ADMM_Z = checkpoint['admm']['ADMM_Z']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resnet18_1by16_pretrained.pt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.load_model = config.load_model.replace('w', str(config.w))\n",
    "config.load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLossMaybeSmooth(smooth_eps=config.smooth_eps).cuda(config.gpu)\n",
    "config.smooth = config.smooth_eps > 0.0\n",
    "config.mixup = config.alpha > 0.0\n",
    "\n",
    "\n",
    "config.warmup = (not config.admm) and config.warmup_epochs > 0\n",
    "optimizer_init_lr = config.warmup_lr if config.warmup else config.lr\n",
    "\n",
    "optimizer = None\n",
    "if (config.optimizer == 'sgd'):\n",
    "    optimizer = torch.optim.SGD(config.model.parameters(), optimizer_init_lr,\n",
    "                            momentum=0.9,\n",
    "                                weight_decay=1e-4)\n",
    "elif (config.optimizer =='adam'):\n",
    "    optimizer = torch.optim.Adam(config.model.parameters(), optimizer_init_lr)\n",
    "    \n",
    "scheduler = None\n",
    "if config.lr_scheduler == 'cosine':\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs*len(trainloader), eta_min=4e-08)\n",
    "elif config.lr_scheduler == 'default':\n",
    "    # my learning rate scheduler for cifar, following https://github.com/kuangliu/pytorch-cifar\n",
    "    epoch_milestones = [150, 250, 350]\n",
    "\n",
    "    \"\"\"Set the learning rate of each parameter group to the initial lr decayed\n",
    "        by gamma once the number of epoch reaches one of the milestones\n",
    "    \"\"\"\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[i*len(trainloader) for i in epoch_milestones], gamma=0.1)\n",
    "else:\n",
    "    raise Exception(\"unknown lr scheduler\")\n",
    "\n",
    "if config.warmup:\n",
    "    scheduler = GradualWarmupScheduler(optimizer, multiplier=config.lr/config.warmup_lr, total_iter=config.warmup_epochs*len(trainloader), after_scheduler=scheduler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('adam', False, 'resnet18_wby16_pretrained.pt')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.optimizer, config.masked_retrain, config.save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valiadtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from cifar10.models import ResNet18_wby16\n",
    "from cifar10.config import Config\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from cifar10.models import ResNet18_wby16\n",
    "from admm.cross_entropy import CrossEntropyLossMaybeSmooth\n",
    "from admm.admm import test_sparsity\n",
    "import time\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "def validate(val_loader, criterion, config):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    config.model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            if config.gpu is not None:\n",
    "                input = input.cuda(config.gpu, non_blocking=True)\n",
    "            target = target.cuda(config.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = config.model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(acc1[0], input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % config.print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      .format(\n",
    "                          i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                          top1=top1))\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f} '\n",
    "              .format(top1=top1))\n",
    "\n",
    "\n",
    "    return top1.avg\n",
    "# get configuration\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "parser.add_argument('--config_file', type=str, default='./cifar10/natural/config_w16.yaml', help =\"config file\")\n",
    "parser.add_argument('--stage', type=str, default='pretrain', help =\"select the pruning stage\")\n",
    "args = parser.parse_args(\"\")\n",
    "config = Config(args)\n",
    "criterion = CrossEntropyLossMaybeSmooth(smooth_eps=config.smooth_eps).cuda(config.gpu)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=config.workers)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ResNet18_wby16(16)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "checkpoint = torch.load('./cifar10/trainedMod/resnet18_16by16_pretrained.pt', map_location=torch.device(device))\n",
    "net.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/100]\tTime 3.162 (3.162)\tLoss 0.3306 (0.3306)\tAcc@1 95.000 (95.000)\t\n",
      "Test: [10/100]\tTime 0.063 (0.348)\tLoss 0.1819 (0.5375)\tAcc@1 97.000 (93.455)\t\n",
      "Test: [20/100]\tTime 0.061 (0.212)\tLoss 0.7931 (0.5728)\tAcc@1 93.000 (93.143)\t\n",
      "Test: [30/100]\tTime 0.064 (0.164)\tLoss 0.5674 (0.6170)\tAcc@1 92.000 (93.097)\t\n",
      "Test: [40/100]\tTime 0.063 (0.139)\tLoss 1.0210 (0.6508)\tAcc@1 90.000 (92.659)\t\n",
      "Test: [50/100]\tTime 0.063 (0.124)\tLoss 0.2226 (0.6480)\tAcc@1 96.000 (92.843)\t\n",
      "Test: [60/100]\tTime 0.063 (0.114)\tLoss 0.4355 (0.6285)\tAcc@1 95.000 (93.049)\t\n",
      "Test: [70/100]\tTime 0.063 (0.107)\tLoss 1.2535 (0.6035)\tAcc@1 88.000 (93.239)\t\n",
      "Test: [80/100]\tTime 0.063 (0.102)\tLoss 0.4119 (0.6038)\tAcc@1 95.000 (93.222)\t\n",
      "Test: [90/100]\tTime 0.063 (0.097)\tLoss 0.5485 (0.5946)\tAcc@1 93.000 (93.253)\t\n",
      " * Acc@1 93.240 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(93.2400, device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.model = net\n",
    "validate(testloader, criterion, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "parser.add_argument('--config_file', type=str, default='./cifar10/prune/config_w16.yaml', help =\"config file\")\n",
    "parser.add_argument('--stage', type=str, default='admm', help =\"select the pruning stage\")\n",
    "args = parser.parse_args(\"\")\n",
    "config = Config(args)\n",
    "\n",
    "netadmm = ResNet18_wby16(16)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "netadmm.to(device)\n",
    "netadmm = torch.nn.DataParallel(netadmm)\n",
    "checkpoint = torch.load('./cifar10/trainedMod/resnet18_16by16_admm.pt', map_location=torch.device(device))\n",
    "netadmm.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/100]\tTime 0.675 (0.675)\tLoss 0.2687 (0.2687)\tAcc@1 95.000 (95.000)\t\n",
      "Test: [10/100]\tTime 0.063 (0.122)\tLoss 0.1380 (0.5242)\tAcc@1 97.000 (92.909)\t\n",
      "Test: [20/100]\tTime 0.063 (0.094)\tLoss 0.9564 (0.5891)\tAcc@1 91.000 (93.000)\t\n",
      "Test: [30/100]\tTime 0.064 (0.084)\tLoss 0.9202 (0.6507)\tAcc@1 93.000 (92.806)\t\n",
      "Test: [40/100]\tTime 0.063 (0.079)\tLoss 0.9842 (0.6808)\tAcc@1 90.000 (92.463)\t\n",
      "Test: [50/100]\tTime 0.063 (0.075)\tLoss 0.2072 (0.6856)\tAcc@1 94.000 (92.569)\t\n",
      "Test: [60/100]\tTime 0.062 (0.074)\tLoss 0.5158 (0.6786)\tAcc@1 94.000 (92.672)\t\n",
      "Test: [70/100]\tTime 0.063 (0.072)\tLoss 1.2127 (0.6576)\tAcc@1 88.000 (92.803)\t\n",
      "Test: [80/100]\tTime 0.062 (0.071)\tLoss 0.4642 (0.6551)\tAcc@1 95.000 (92.765)\t\n",
      "Test: [90/100]\tTime 0.062 (0.070)\tLoss 0.6394 (0.6443)\tAcc@1 94.000 (92.791)\t\n",
      " * Acc@1 92.830 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(92.8300, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.model = netadmm\n",
    "validate(testloader, criterion, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'module', 'module.conv1', 'module.bn1', 'module.layer1', 'module.layer1.0', 'module.layer1.0.conv1', 'module.layer1.0.bn1', 'module.layer1.0.conv2', 'module.layer1.0.bn2', 'module.layer1.0.shortcut', 'module.layer1.1', 'module.layer1.1.conv1', 'module.layer1.1.bn1', 'module.layer1.1.conv2', 'module.layer1.1.bn2', 'module.layer1.1.shortcut', 'module.layer2', 'module.layer2.0', 'module.layer2.0.conv1', 'module.layer2.0.bn1', 'module.layer2.0.conv2', 'module.layer2.0.bn2', 'module.layer2.0.shortcut', 'module.layer2.0.shortcut.0', 'module.layer2.0.shortcut.1', 'module.layer2.1', 'module.layer2.1.conv1', 'module.layer2.1.bn1', 'module.layer2.1.conv2', 'module.layer2.1.bn2', 'module.layer2.1.shortcut', 'module.layer3', 'module.layer3.0', 'module.layer3.0.conv1', 'module.layer3.0.bn1', 'module.layer3.0.conv2', 'module.layer3.0.bn2', 'module.layer3.0.shortcut', 'module.layer3.0.shortcut.0', 'module.layer3.0.shortcut.1', 'module.layer3.1', 'module.layer3.1.conv1', 'module.layer3.1.bn1', 'module.layer3.1.conv2', 'module.layer3.1.bn2', 'module.layer3.1.shortcut', 'module.layer4', 'module.layer4.0', 'module.layer4.0.conv1', 'module.layer4.0.bn1', 'module.layer4.0.conv2', 'module.layer4.0.bn2', 'module.layer4.0.shortcut', 'module.layer4.0.shortcut.0', 'module.layer4.0.shortcut.1', 'module.layer4.1', 'module.layer4.1.conv1', 'module.layer4.1.bn1', 'module.layer4.1.conv2', 'module.layer4.1.bn2', 'module.layer4.1.shortcut', 'module.linear']\n"
     ]
    }
   ],
   "source": [
    "from numpy import linalg as LA\n",
    "import admm\n",
    "import numpy as np\n",
    "config.prepare_pruning() \n",
    "ADMM = admm.ADMM(config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sparsity(config):\n",
    "    \"\"\"\n",
    "    test sparsity for every involved layer and the overall compression rate\n",
    "\n",
    "    \"\"\"\n",
    "    total_zeros = 0\n",
    "    total_nonzeros = 0\n",
    "\n",
    "    print('<===sparsity type is {}'.format(config.sparsity_type))\n",
    "    print('<===layers to be pruned are \\n{}'.format(config._prune_ratios))\n",
    "    if config.sparsity_type == \"irregular\":\n",
    "        for name, W in config.model.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                continue\n",
    "            W = W.cpu().detach().numpy()\n",
    "            zeros = np.sum(W == 0)\n",
    "            total_zeros += zeros\n",
    "            nonzeros = np.sum(W != 0)\n",
    "            total_nonzeros += nonzeros\n",
    "            print(\"sparsity at layer {} is {}\".format(name, zeros / (zeros + nonzeros)))\n",
    "        total_weight_number = total_zeros + total_nonzeros\n",
    "        print('overal compression rate is {}'.format(total_weight_number / total_nonzeros))\n",
    "    elif config.sparsity_type == \"filter\":\n",
    "        print('inside if')\n",
    "        print(config.prune_ratios)\n",
    "        for name, W in config.model.named_parameters():\n",
    "            if name not in config.prune_ratios:\n",
    "                continue\n",
    "            W = W.cpu().detach().numpy()\n",
    "            shape = W.shape\n",
    "            W2d = W.reshape(shape[0], -1)\n",
    "            row_l2_norm = LA.norm(W2d, 2, axis=1)\n",
    "            zero_row = np.sum(row_l2_norm == 0)\n",
    "            nonzero_row = np.sum(row_l2_norm != 0)\n",
    "            total_zeros += np.sum(W == 0)\n",
    "            total_nonzeros += np.sum(W != 0)\n",
    "            print(\"filter sparsity of layer {} is {}\".format(name, zero_row / (zero_row + nonzero_row)))\n",
    "#         print('only consider conv layers, compression rate is {}'.format((total_zeros + total_nonzeros) / total_nonzeros))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<===sparsity type is filter\n",
      "<===layers to be pruned are \n",
      "{'conv1.weight': 0.1, 'conv2.weight': 0.2, 'conv3.weight': 0.3, 'conv4.weight': 0.4, 'conv5.weight': 0.5, 'conv6.weight': 0.9375, 'conv7.weight': 0.9375, 'conv8.weight': 0.9375, 'conv9.weight': 0.9375, 'conv10.weight': 0.9375, 'conv11.weight': 0.9375, 'conv12.weight': 0.9375, 'conv13.weight': 0.9375, 'conv14.weight': 0.9375, 'conv15.weight': 0.9375, 'conv16.weight': 0.9375, 'conv17.weight': 0.9375, 'conv18.weight': 0.9375, 'conv19.weight': 0.9375, 'conv20.weight': 0.9375}\n",
      "inside if\n",
      "{'module.conv1.weight': 0.1, 'module.layer1.0.conv1.weight': 0.2, 'module.layer1.0.conv2.weight': 0.3, 'module.layer1.1.conv1.weight': 0.4, 'module.layer1.1.conv2.weight': 0.5, 'module.layer2.0.conv1.weight': 0.9375, 'module.layer2.0.conv2.weight': 0.9375, 'module.layer2.0.shortcut.0.weight': 0.9375, 'module.layer2.1.conv1.weight': 0.9375, 'module.layer2.1.conv2.weight': 0.9375, 'module.layer3.0.conv1.weight': 0.9375, 'module.layer3.0.conv2.weight': 0.9375, 'module.layer3.0.shortcut.0.weight': 0.9375, 'module.layer3.1.conv1.weight': 0.9375, 'module.layer3.1.conv2.weight': 0.9375, 'module.layer4.0.conv1.weight': 0.9375, 'module.layer4.0.conv2.weight': 0.9375, 'module.layer4.0.shortcut.0.weight': 0.9375, 'module.layer4.1.conv1.weight': 0.9375, 'module.layer4.1.conv2.weight': 0.9375}\n",
      "filter sparsity of layer module.conv1.weight is 0.0\n",
      "filter sparsity of layer module.layer1.0.conv1.weight is 0.0\n",
      "filter sparsity of layer module.layer1.0.conv2.weight is 0.0\n",
      "filter sparsity of layer module.layer1.1.conv1.weight is 0.0\n",
      "filter sparsity of layer module.layer1.1.conv2.weight is 0.0\n",
      "filter sparsity of layer module.layer2.0.conv1.weight is 0.0\n",
      "filter sparsity of layer module.layer2.0.conv2.weight is 0.0\n",
      "filter sparsity of layer module.layer2.0.shortcut.0.weight is 0.0\n",
      "filter sparsity of layer module.layer2.1.conv1.weight is 0.0\n",
      "filter sparsity of layer module.layer2.1.conv2.weight is 0.0\n",
      "filter sparsity of layer module.layer3.0.conv1.weight is 0.0\n",
      "filter sparsity of layer module.layer3.0.conv2.weight is 0.0\n",
      "filter sparsity of layer module.layer3.0.shortcut.0.weight is 0.0\n",
      "filter sparsity of layer module.layer3.1.conv1.weight is 0.0\n",
      "filter sparsity of layer module.layer3.1.conv2.weight is 0.0\n",
      "filter sparsity of layer module.layer4.0.conv1.weight is 0.0\n",
      "filter sparsity of layer module.layer4.0.conv2.weight is 0.0\n",
      "filter sparsity of layer module.layer4.0.shortcut.0.weight is 0.0\n",
      "filter sparsity of layer module.layer4.1.conv1.weight is 0.0\n",
      "filter sparsity of layer module.layer4.1.conv2.weight is 0.0\n"
     ]
    }
   ],
   "source": [
    "test_sparsity(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, W in config.model.named_parameters():\n",
    "        if name not in ADMM.prune_ratios:\n",
    "            continue\n",
    "        ADMM.ADMM_Z[name] = W + ADMM.ADMM_U[name]  # Z(k+1) = W(k+1)+U[k]\n",
    "        _, _Z = admm.admm.weight_pruning(config, ADMM.ADMM_Z[name], ADMM.prune_ratios[name])  # equivalent to Euclidean Projection\n",
    "        ADMM.ADMM_Z[name] = _Z\n",
    "        ADMM.ADMM_U[name] = W - ADMM.ADMM_Z[name] + ADMM.ADMM_U[name]  # U(k+1) = W(k+1) - Z(k+1) +U(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter sparsity of layer module.conv1.weight is 0.109375\n",
      "filter sparsity of layer module.layer1.0.conv1.weight is 0.203125\n",
      "filter sparsity of layer module.layer1.0.conv2.weight is 0.296875\n",
      "filter sparsity of layer module.layer1.1.conv1.weight is 0.40625\n",
      "filter sparsity of layer module.layer1.1.conv2.weight is 0.5\n",
      "filter sparsity of layer module.layer2.0.conv1.weight is 0.9375\n",
      "filter sparsity of layer module.layer2.0.conv2.weight is 0.9375\n",
      "filter sparsity of layer module.layer2.0.shortcut.0.weight is 0.9375\n",
      "filter sparsity of layer module.layer2.1.conv1.weight is 0.9375\n",
      "filter sparsity of layer module.layer2.1.conv2.weight is 0.9375\n",
      "filter sparsity of layer module.layer3.0.conv1.weight is 0.9375\n",
      "filter sparsity of layer module.layer3.0.conv2.weight is 0.9375\n",
      "filter sparsity of layer module.layer3.0.shortcut.0.weight is 0.9375\n",
      "filter sparsity of layer module.layer3.1.conv1.weight is 0.9375\n",
      "filter sparsity of layer module.layer3.1.conv2.weight is 0.9375\n",
      "filter sparsity of layer module.layer4.0.conv1.weight is 0.9375\n",
      "filter sparsity of layer module.layer4.0.conv2.weight is 0.9375\n",
      "filter sparsity of layer module.layer4.0.shortcut.0.weight is 0.9375\n",
      "filter sparsity of layer module.layer4.1.conv1.weight is 0.9375\n",
      "filter sparsity of layer module.layer4.1.conv2.weight is 0.9375\n"
     ]
    }
   ],
   "source": [
    "total_zeros = 0\n",
    "total_nonzeros = 0\n",
    "for name, W in ADMM.ADMM_Z.items():\n",
    "    if name not in config.prune_ratios:\n",
    "        continue\n",
    "    W = W.cpu().detach().numpy()\n",
    "    shape = W.shape\n",
    "    W2d = W.reshape(shape[0], -1)\n",
    "    row_l2_norm = LA.norm(W2d, 2, axis=1)\n",
    "    zero_row = np.sum(row_l2_norm == 0)\n",
    "    nonzero_row = np.sum(row_l2_norm != 0)\n",
    "    total_zeros += np.sum(W == 0)\n",
    "    total_nonzeros += np.sum(W != 0)\n",
    "    print(\"filter sparsity of layer {} is {}\".format(name, zero_row / (zero_row + nonzero_row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
